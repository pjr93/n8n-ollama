version: '3'
services:
  llm-server:
    build:
      context: ./llm-server
      dockerfile: DockerfileServer
    tty: true #idk but it keeps it running without hanging
    stdin_open: true #allows you to type when attaching to the container
    environment:
      - OLLAMA_HOST=0.0.0.0:11434 #ensure it listens on all interfaces
    command: ollama serve
    ports:
      - "49153:11434" # can access externally
    networks:
      - llm-connection

  n8n:
    image: docker.n8n.io/n8nio/n8n
    tty: true
    stdin_open: true
    volumes:
      - ./n8n_data:/home/node/.n8n
    environment:
      - N8N_RUNNERS_ENABLED=true
      - OLLAMA_HOST=llm-server:11434
    ports:
      - "5678:5678"
    networks:
      - llm-connection

networks:
  llm-connection:
    driver: bridge